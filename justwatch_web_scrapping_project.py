# -*- coding: utf-8 -*-
"""JustWatch_Web_Scrapping_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lGnblHeX2ITsx1ZYilafXH1_2lIvaEjg

## **Web Scrapping**
"""

#Installing all necessary labraries
!pip install bs4
!pip install requests

#import all necessary labraries
import requests
from bs4 import BeautifulSoup
import re
import pandas as pd
import numpy as np
headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'
        }

"""## **Scrapping Movies Data**"""

def fetch_movie_urls(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'
    }
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        return "Failed to retrieve the page, status code:", response.status_code
    soup = BeautifulSoup(response.text, 'html.parser')
    return soup


url = 'https://www.justwatch.com/in/movies?release_year_from=2000'
soup=fetch_movie_urls(url)
print(soup.prettify())

"""## **Fetching Movie URL's**"""

# Movie url

movie_links = soup.find_all('a', href=True)
movie_urls = [link['href'] for link in movie_links if '/movie/' in link['href']]

url_list=[]
for x in movie_urls:
  url_list.append('https://www.justwatch.com'+x)

for movie_url in url_list:
    print(movie_url)

"""## **Scrapping Movie Title**"""

import requests
from bs4 import BeautifulSoup

# Function to fetch and parse HTML from a URL
def fetch_soup(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'
    }
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        return BeautifulSoup(response.text, 'html.parser')
    else:
        print(f"Failed to retrieve {url}, status code: {response.status_code}")
        return None

# Get the main movies page and extract movie URLs
main_url = 'https://www.justwatch.com/in/movies?release_year_from=2000'
soup = fetch_soup(main_url)

movie_urls = []
if soup:
    movie_links = soup.find_all('a', href=True)
    movie_urls = [link['href'] for link in movie_links if '/movie/' in link['href']]
    url_list = ['https://www.justwatch.com' + x for x in movie_urls]
else:
    url_list = []

#  Loop through each movie URL to extract and store title:url in dict
Movie_title = {}

for movie_url in url_list:
    movie_soup = fetch_soup(movie_url)
    if movie_soup:
        title_tag = movie_soup.find('h1', class_='title-detail-hero__details__title')
        if title_tag:
            # Extract only direct text (ignore nested span)
            title = title_tag.find(string=True, recursive=False).strip()
            Movie_title[title] = movie_url
        else:
            Movie_title["Title not found"] = movie_url

# Print the resulting dictionary
for title, url in Movie_title.items():
    print(f"{title}: {url}")

"""## **Scrapping release Year**"""

import requests
from bs4 import BeautifulSoup

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'
}

movie_release_year = {}

for url in url_list:
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "html.parser")

        # Extract the movie title
        title_tag = soup.find("h1", class_="title-detail-hero__details__title")
        title = title_tag.find(string=True, recursive=False).strip() if title_tag else "Title not found"

        # Extract the release year
        year_span = soup.find("span", class_="release-year")
        release_year = year_span.text.strip("()").strip() if year_span else "Year not found"

        movie_release_year[title] = release_year
    else:
        movie_release_year[url] = f"Failed to retrieve, status code {response.status_code}"

# Print the dictionary of movie titles with their release years
for title, year in movie_release_year.items():
    print(f"{title}: {year}")

"""## **Scrapping Genres**"""

movie_genres = {}

for url in url_list:
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'
        }
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "html.parser")
        # Extract the movie title
        title_tag = soup.find("h1", class_="title-detail-hero__details__title")
        title = title_tag.find(string=True, recursive=False).strip() if title_tag else "Title not found"

        # Find all poster-detail-infos blocks
        infos = soup.find_all("div", class_="poster-detail-infos")

        genres = "Genres not found"

        for info in infos:
            # genres are stored in the h3 heading inside class_="poster-detail-infos__subheading block
            heading = info.find("h3", class_="poster-detail-infos__subheading")
            if heading and heading.get_text(strip=True) == "Genres":
                # nested div with class poster-detail-infos__value inside the same block
                value_div = info.find("div", class_="poster-detail-infos__value")
                if value_div:
                    genre_span = value_div.find("span")
                    if genre_span:
                        genres = genre_span.get_text(strip=True)
                break

        #print(genres)
        movie_genres[title] = genres
    else:
        print(f"Failed to retrieve {url}, status: {response.status_code}")

for title, genres in movie_genres.items():
     print(f"{title}:  {genres}")

"""## **Scrapping IMBD Rating**"""

movie_rating = {}  # Dictionary to store title: rating pairs

for url in url_list:
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "html.parser")

        # Extract the movie title
        title_tag = soup.find("h1", class_="title-detail-hero__details__title")
        title = title_tag.find(string=True, recursive=False).strip() if title_tag else "Title not found"

        # Extract the IMDb rating
        rating_span = soup.find("span", class_="imdb-score")
        if rating_span:
            imdb_text = rating_span.get_text(strip=True)
            match = re.search(r"\d+(\.\d+)?", imdb_text)
            rating = float(match.group(0)) if match else None
        else:
            rating = None

        movie_rating[title] = rating
    else:
        movie_rating[url] = None

# Print the movie titles with their ratings
for title, rating in movie_rating.items():
    print(f"{title} : {rating}")

"""## **Scrapping Runtime/Duration**"""

import re

Movie_Runtime = {}  # store all runtimes

for url in url_list:
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "html.parser")

        # Extract the movie title
        title_tag = soup.find("h1", class_="title-detail-hero__details__title")
        title = title_tag.find(string=True, recursive=False).strip() if title_tag else "Title not found"

        # Find the block containing runtime text
        runtime_tag = soup.find("div", class_="hidden-horizontal-scrollbar__items")
        if runtime_tag:
            all_text = runtime_tag.get_text(strip=True)
            # Regex to find runtime like '2h 17min', '1h', or '98min'
            match = re.search(r"\d+\s*h\s*\d*\s*min|\d+\s*h|\d+\s*min", all_text)
            if match:
                runtime = match.group(0)

            else:
                runtime = "Runtime not found"
        else:
            runtime = "Runtime not found"
        Movie_Runtime[title] = runtime
    else:
        Movie_Runtime[url] = f"Failed to retrieve (status {response.status_code})"

    #Runtime_list.append(runtime, title)

for title, runtime in Movie_Runtime.items():
    print(f"{title} : {runtime}")

"""## **Scrapping Age Rating**"""

# Write Your Code here


Age_Rating_list = {}  # store all extracted values

for url in url_list:
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "html.parser")

        # Extract the movie title
        title_tag = soup.find("h1", class_="title-detail-hero__details__title")
        title = title_tag.find(string=True, recursive=False).strip() if title_tag else "Title not found"

        rating_tag = soup.find("div", class_="hidden-horizontal-scrollbar__items")
        if rating_tag:
            all_text = rating_tag.get_text(strip=True)
            # This will extract character(s) before 'Age rating'
            match = re.search(r'([A-Za-z0-9\+]+)\s*Age rating', all_text)
            if match:
                # group(1) is the value before 'Age rating'
                age_rating = match.group(1)
            else:
                age_rating = "Age Rating not found"
        else:
            age_rating = "Tag not found"
        Age_Rating_list[title]= age_rating
    else:
        Age_Rating_list[url] = f"Failed to retrieve (status {response.status_code})"


# Print all values
for title, age_rating in Age_Rating_list.items():
    print(f"{title} : {age_rating}")

"""## **Fetching Production Countries Details**"""

movie_production_country = {}

for url in url_list:
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "html.parser")

        # Extract the movie title
        title_tag = soup.find("h1", class_="title-detail-hero__details__title")
        title = title_tag.find(string=True, recursive=False).strip() if title_tag else "Title not found"

        production_country = "Country not found"
        infos = soup.find_all("div", class_="poster-detail-infos")
        for info in infos:
            heading = info.find("h3", class_="poster-detail-infos__subheading")
            if heading and heading.get_text(strip=True).lower() == "production country":
                value_div = info.find("div", class_="poster-detail-infos__value")
                if value_div:
                    production_country = value_div.get_text(strip=True)
                break

        # Add to dictionary
        movie_production_country[title] = production_country
    else:
        movie_production_country[url] = f"Failed to retrieve (status {response.status_code})"

for title, country in movie_production_country.items():
    print(f"{title}:  {country}")

"""## **Fetching Streaming Service Details**"""

import requests
from bs4 import BeautifulSoup

Movie_streaming_Platform= {}  # store providers from all URLs

for url in url_list:
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "html.parser")

        # Extract the movie title
        title_tag = soup.find("h1", class_="title-detail-hero__details__title")
        title = title_tag.find(string=True, recursive=False).strip() if title_tag else "Title not found"

        # Find all offer-container blocks
        offer_blocks = soup.find_all("span", class_="offer-container")

        platform = []  # platform for this URL only
        for block in offer_blocks:
            img_tag = block.find("img", class_="provider-icon")
            if img_tag and img_tag.has_attr("title"):
                platform.append(img_tag["title"])


        if platform:
          Movie_streaming_Platform[title] = platform
        else:
          Movie_streaming_Platform[title] = ["Not available for streaming"]

for title, platform in Movie_streaming_Platform.items():
    print(f"Title: {title}")
    print("Movie_streaming_Platform:", platform, "\n")

"""## **Now Creating Movies DataFrame**"""

import pandas as pd


# Combine all into one
final_movie_dict = {}

# collect all titles across dictionaries
all_titles = set(
    list(Movie_title.keys())
    + list(movie_release_year.keys())
    + list(movie_genres.keys())
    + list(movie_rating.keys())
    + list(Movie_Runtime.keys())
    + list(Age_Rating_list.keys())
    + list(movie_production_country.keys())
    + list(Movie_streaming_Platform.keys())
)

for title in all_titles:
    final_movie_dict[title] = {
        "title": title,
        "release_year": movie_release_year.get(title, "N/A"),
        "genres": ", ".join(movie_genres.get(title, [])) if isinstance(movie_genres.get(title), list) else movie_genres.get(title, "N/A"),
        "rating": movie_rating.get(title, "N/A"),
        "runtime": Movie_Runtime.get(title, "N/A"),
        "age_rating": Age_Rating_list.get(title, "N/A"),
        "country": movie_production_country.get(title, "N/A"),
        "platforms": ", ".join(Movie_streaming_Platform.get(title, [])) if isinstance(Movie_streaming_Platform.get(title), list) else Movie_streaming_Platform.get(title, "N/A"),
        "url": Movie_title.get(title, "N/A")

    }


# Print the  dictionary
import pprint
pprint.pprint(final_movie_dict, width=200)

#Create Data Frame
df_Movie = pd.DataFrame.from_dict(final_movie_dict, orient="index")
df_Movie.reset_index(drop=True, inplace=True)
df_Movie

"""## **Scraping TV  Show Data**"""

!pip install bs4
!pip install requests
import requests
from bs4 import BeautifulSoup
import re
import pandas as pd
import numpy as np
headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'
        }

import requests
from bs4 import BeautifulSoup

# Function to fetch and parse HTML from a URL
def fetch_tv_soup(tv_url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'
    }

    response = requests.get(tv_url, headers=headers)
    if response.status_code == 200:
        return  BeautifulSoup(response.text, 'html.parser')
    else:
        print(f"Failed to retrieve {url}, status code: {response.status_code}")
        return None

base_url = 'https://www.justwatch.com'
tv_url = f"{base_url}/in/tv-shows?release_year_from=2000"
tv_soup = fetch_tv_soup(tv_url)
print(tv_soup.prettify())

"""## **Fetching Tv shows Url details**"""

tv_links = tv_soup.find_all('a', href=True)

show_urls = list(set(
    base_url + link['href']
    for link in tv_links if '/tv-show/' in link['href'] and '/season-' not in link['href']
))



#  For each show, fetch season URLs too
tv_show_url = []

for show_url in show_urls:
    try:
        resp = requests.get(show_url, headers=headers)
        if resp.status_code != 200:
            print(f" Failed to fetch {show_url}")
            continue

        detail_soup = BeautifulSoup(resp.text, 'html.parser')

        # Collect base show URL
        tv_show_url.append(show_url)

        # Look for season links
        season_links = detail_soup.find_all('a', href=True)
        for link in season_links:
            href = link['href']
            if href.startswith('/in/tv-show/') and '/season-' in href:
                season_url = base_url + href
                tv_show_url.append(season_url)

    except Exception as e:
        print(f"Error with {show_url}: {e}")

# Remove duplicates
tv_show_urls_list = list(set(tv_show_url))


for url in tv_show_urls_list:
    print(url)

"""## **Fetching Tv Show Title details**"""

Tv_shows_title_list = []  # Dictionary to store url: title pairs

for tv_url in tv_show_urls_list:
    tv_tag1 = fetch_tv_soup(tv_url)
    if tv_tag1:
        title_tag = tv_tag1.find('h1', class_='title-detail-hero__details__title')
        if title_tag:
            # Case 1: Shows with nested <a><span> and season text after
            link_tag = title_tag.find('a')
            if link_tag:
                # Extract the text inside span (show name)
                span = link_tag.find('span')
                title = span.get_text(strip=True) if span else link_tag.get_text(strip=True)

                # Extract the tail text after </a>, e.g. " - Season 3"
                # It's a NavigableString immediately following the <a>
                next_text = title_tag.find(string=True, recursive=False)
                if next_text:
                    next_text = next_text.strip()
                    title = f"{title} {next_text}".strip()

            else:
                # Case 2: Direct text title (no nested <a>), e.g. "Mayasabha: Rise of the Titans"
                # Extract only direct text ignoring nested spans like release year
                title = title_tag.find(string=True, recursive=False)
                if title:
                    title = title.strip()
                else:
                    title = "NaN/Title Missing"

            Tv_shows_title_list.append(title)
        else:
            Tv_shows_title_list.append("NaN/Title Missing")
    else:
        Tv_shows_title_list.append( "Soup Not Retrieved")

# Print the resulting dictionary
for title in Tv_shows_title_list:
    print(title)

"""## **Fetching Release Year**"""

tvshow_release_year = []
# Write Your Code here
for url in tv_show_urls_list:
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "html.parser")

        # # Extract the movie title
        # title_tag = soup.find("h1", class_="title-detail-hero__details__title")
        # title = title_tag.find(string=True, recursive=False).strip() if title_tag else "Title not found"

        # Extract the release year
        year_span = soup.find("span", class_="release-year")
        release_year = year_span.text.strip("()").strip() if year_span else "Year not found"

        tvshow_release_year.append(release_year)
    else:
        tvshow_release_year.append("NaN/Title Missing")

for release_year in tvshow_release_year:
    print(release_year)

"""## **Fetching TV Show Genre Details**"""

# Write Your Code here
tvshow_genres = []

for url in tv_show_urls_list:
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "html.parser")

        infos = soup.find_all("div", class_="poster-detail-infos")

        genres = "Genres not found"

        for info in infos:
            # genres are stored in the h3 heading inside class_="poster-detail-infos__subheading block
            heading = info.find("h3", class_="poster-detail-infos__subheading")
            if heading and heading.get_text(strip=True) == "Genres":
                # Find the nested div with class poster-detail-infos__value inside the same block
                value_div = info.find("div", class_="poster-detail-infos__value")
                if value_div:
                    genre_span = value_div.find("span")
                    if genre_span:
                        genres = genre_span.get_text(strip=True)
                break  # Stop after finding the genres block

        #print(genres)
        tvshow_genres.append(genres)
    else:
        print(f"Failed to retrieve {url}, status: {response.status_code}")

for genres in tvshow_genres:
     print(genres)

"""
## **Fetching IMDB Rating Details**"""

tvshow_imdb_rating = []
# Write Your Code here

for url in tv_show_urls_list:
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "html.parser")

          # Extract the IMDb rating
        rating_span = soup.find("span", class_="imdb-score")
        if rating_span:
            imdb_text = rating_span.get_text(strip=True)
            match = re.search(r"\d+(\.\d+)?", imdb_text)
            rating = float(match.group(0)) if match else None
        else:
            rating = None

        tvshow_imdb_rating.append(rating)
    else:
        tvshow_imdb_rating.append("NaN")

# Print the movie titles with their ratings
for rating in tvshow_imdb_rating:
    print(rating)

"""## **Fetching Age Rating Details**"""

tvshow_Age_Rating_list = []  # store all extracted values

for url in tv_show_urls_list:
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "html.parser")
        rating_tag = soup.find("div", class_="hidden-horizontal-scrollbar__items")
        if rating_tag:
            all_text = rating_tag.get_text(strip=True)
            # This will extract character(s) before 'Age rating'
            match = re.search(r'([A-Za-z0-9\+]+)\s*Age rating', all_text)
            if match:
                # group(1) is the value before 'Age rating'
                age_rating = match.group(1)
            else:
                age_rating = "NaN"
        else:
            age_rating = "Tag not found"
        tvshow_Age_Rating_list.append(age_rating)
    else:
        tvshow_Age_Rating_list.append(f"Failed to retrieve (status {response.status_code})")


# Print all values
for tvshowage_rating in tvshow_Age_Rating_list:
    print(tvshowage_rating)

"""## **Fetching Production Country details**"""

# Write Your Code here
tvshow_production_country = []

for url in tv_show_urls_list:
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "html.parser")

        production_country = "Country not found"
        infos = soup.find_all("div", class_="poster-detail-infos")
        for info in infos:
            heading = info.find("h3", class_="poster-detail-infos__subheading")
            if heading and heading.get_text(strip=True).lower() == "production country":
                value_div = info.find("div", class_="poster-detail-infos__value")
                if value_div:
                    production_country = value_div.get_text(strip=True)
                break
        tvshow_production_country.append(production_country)
    else:
        tvshow_production_country.append(f"Failed to retrieve (status {response.status_code})",url)

for country in tvshow_production_country:
    print(country)

"""## **Fetching Streaming Service details**"""

# Write Your Code here
import requests
from bs4 import BeautifulSoup

tvshow_streaming_platform= []

for url in tv_show_urls_list:
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "html.parser")
        # Find all offer-container blocks
        offer_blocks = soup.find_all("span", class_="offer-container")

        platform = []  # platform for this URL only
        for block in offer_blocks:
            img_tag = block.find("img", class_="provider-icon")
            if img_tag and img_tag.has_attr("title"):
                platform.append(img_tag["title"])
        if platform:
          tvshow_streaming_platform.append(platform)
        else:
          tvshow_streaming_platform.append("Not available for streaming")

for platform in tvshow_streaming_platform:
    print(platform)

"""## **Fetching Duration Details**"""

# Write Your Code here
import re

tvshow_runtime = []

for url in tv_show_urls_list:
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "html.parser")
        # Find the block containing runtime text
        runtime_tag = soup.find("div", class_="hidden-horizontal-scrollbar__items")
        if runtime_tag:
            all_text = runtime_tag.get_text(strip=True)
            # Regex to find runtime like '2h 17min', '1h', or '98min'
            match = re.search(r"\d+\s*h\s*\d*\s*min|\d+\s*h|\d+\s*min", all_text)
            if match:
                runtime_show = match.group(0)
                runtime_show+= " per Episode"

            else:
                runtime_show = "Runtime not found"
        else:
            runtime_show = "Runtime not found"
        tvshow_runtime.append(runtime_show)
    else:
        tvshow_runtime.append(f"Failed to retrieve (status {response.status_code})")

for time in tvshow_runtime:
    print(time)

"""## **Creating TV Show DataFrame**"""

from typing_extensions import dataclass_transform
# Write Your Code here
data_tv_show={
    "Show Title": Tv_shows_title_list,
    "Show Release Year":tvshow_release_year,
    "Show Genres": tvshow_genres,
    "Show Rating": tvshow_imdb_rating,
    "Show Age Category": tvshow_Age_Rating_list,
    "Show Production Country" : tvshow_production_country,
    "Show Streaming Platform": tvshow_streaming_platform,
    "Show Runtime per episode": tvshow_runtime,
    "Show URL": tv_show_urls_list
}

Tv_Shows_df = pd.DataFrame(data_tv_show)
#convert the Show Streaming Platfrom Column data type from list to string
Tv_Shows_df["Show Streaming Platform"] = Tv_Shows_df["Show Streaming Platform"].apply(
    lambda x: ", ".join(map(str, x)) if isinstance(x, list) else str(x)
)

Tv_Shows_df

"""## **Data Filtering & Analysis**"""

# Filter Movie data to show only the details of movies that have been released from the year 2023 to 2025 and have a rating higher than 7.0
# Converting the data type of release year and rating to numeric
df_Movie["release_year"] = pd.to_numeric(df_Movie["release_year"], errors="coerce").fillna(0).astype(int)
df_Movie["rating"] = pd.to_numeric(df_Movie["rating"], errors="coerce")

start_date = 2023
end_date = 2025
min_rating = 7.0
filter_Moviedata_df = df_Movie[(df_Movie["release_year"] >= start_date) & (df_Movie["release_year"] <= end_date) & (df_Movie["rating"] >= min_rating)]
filter_Moviedata_df

# Filter Movie data to show only the details of movies that have been released from the year 2024 to 2025 and have a rating higher than 8.0
# Converting the data type of release year and rating to numeric
Tv_Shows_df["Show Release Year"] = pd.to_numeric(Tv_Shows_df["Show Release Year"], errors="coerce").fillna(0).astype(int)
Tv_Shows_df["Show Rating"] = pd.to_numeric(Tv_Shows_df["Show Rating"], errors="coerce")

start_date = 2024
end_date = 2025
min_rating = 8.0
filter_TvShowdata_df = Tv_Shows_df[(Tv_Shows_df["Show Release Year"] >= start_date) & (Tv_Shows_df["Show Release Year"] <= end_date) & (Tv_Shows_df["Show Rating"] >= min_rating)]
filter_TvShowdata_df

"""## **Calculating Mean IMDB Ratings for both Movies and Tv Shows**"""

# Write Your Code here
# Calculating Movies mean IMDb rating
movie_mean_imdb = df_Movie['rating'].mean()
movie_mean_imdb_rounded = round(movie_mean_imdb, 2)
print("Mean IMDb Rating for Movies is:", movie_mean_imdb_rounded)

# Calculating Tv Shows mean IMDb rating
Tv_Show_mean_imdb = Tv_Shows_df['Show Rating'].mean()
Tv_SHow_mean_imdb_rounded = round(Tv_Show_mean_imdb, 2)
print("Mean IMDb Rating for Tv Shows is:", Tv_SHow_mean_imdb_rounded)

"""## **Analyzing Top Genres**"""

!pip install wordcloud matplotlib numpy Pillow
import numpy as np
from PIL import Image
from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt
from collections import Counter

#top 5 Genre of Tv Shows

# Create a list of genres present in the Show Genres column of the TV show data frame. Split by comma and strip spaces
tvshow_genres_list = [p.strip() for row in Tv_Shows_df["Show Genres"] for p in row.split(",")]

TVshow_genre_count = Counter(tvshow_genres_list)

#Converted into data frame for better view
Top5_TV_Genre = pd.DataFrame(TVshow_genre_count.items(), columns=["Genre", "Count"])
Top5_TV_Genre = Top5_TV_Genre.sort_values(by="Count", ascending=False).reset_index(drop=True,  )

#Print Top 5 Tv Show genre
print("Top5_TV_Genre\n", Top5_TV_Genre[:5])

#top 5 genres of Movies

# Create a list of genres present in the genres column of the Movie data frame. Split by comma and strip spaces
movie_genres_list = [p.strip() for row in df_Movie["genres"] for p in row.split(",")]

Movie_genre_count = Counter(movie_genres_list)

#Converted into data frame for better view
Top5_Movie_Genre = pd.DataFrame(Movie_genre_count.items(), columns=["Genre", "Count"])
Top5_Movie_Genre = Top5_Movie_Genre.sort_values(by="Count", ascending=False).reset_index(drop=True,  )

#Print Top 5 Tv Show genre
print("Top5_Movie_Genre\n", Top5_Movie_Genre[:5])

#Top 5 Genre for combined data

# Concatenated both lists
Genre_list= movie_genres_list + tvshow_genres_list

genre_counts = Counter(Genre_list)

# Step 3: Convert to DataFrame
df_Genre_counts = pd.DataFrame(genre_counts.items(), columns=["Genre", "Count"])

# Step 4: Sort by frequency (descending)
df_Genre_counts = df_Genre_counts.sort_values(by="Count", ascending=False).reset_index(drop=True,  )

print("Top5 Genre Combined\n",df_Genre_counts[:5])

# Convert to dict {Genre: count}
genre_dict = dict(zip(df_Genre_counts["Genre"], df_Genre_counts["Count"]))

# Generate word cloud
wordcloud_genre = WordCloud(width=800, height=400, background_color="white").generate_from_frequencies(genre_dict)

# Display
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud_genre, interpolation="bilinear")
plt.axis("off")
plt.show()

"""## **Finding Predominant Streaming Service**"""

#Top Straming Platform For TV Shows

# Create a list of genres present in the Show Genres column of the TV show data frame. Split by comma and strip spaces
tvshow_streaming_list = [p.strip() for row in Tv_Shows_df["Show Streaming Platform"] for p in row.split(",")]
#top 5 Genre of Tv Shows
TVshow_Streaming_count = Counter(tvshow_streaming_list)


#Converted into data frame for better view
Top5_TV_Show_Streaming_Platform = pd.DataFrame(TVshow_Streaming_count.items(), columns=["Streaming Platfform", "Count"])
Top5_TV_Show_Streaming_Platform  = Top5_TV_Show_Streaming_Platform .sort_values(by="Count", ascending=False).reset_index(drop=True,  )

#Print Top 5 Tv Show genre
print("Top5 TV Show Streaming Platorm\n", Top5_TV_Show_Streaming_Platform[:5])

#top 5 Streaming Platforms of Movies

# Create a list of genres present in the genres column of the Movie data frame. Split by comma and strip spaces
movie_streaming_list = [p.strip() for row in df_Movie["platforms"] for p in row.split(",")]

Movie_Streaming_count = Counter(movie_streaming_list)
#print(Movie_Streaming_count)

#Converted into data frame for better view
Top5_Movie_Streaming_Platform = pd.DataFrame(Movie_Streaming_count.items(), columns=["Streaming Platform", "Count"])
Top5_Movie_Streaming_Platform = Top5_Movie_Streaming_Platform.sort_values(by="Count", ascending=False).reset_index(drop=True,  )

#Print Top 5 Tv Show Streaming Platforms
print("Top5 Movie Streaming Platform Available\n\n", Top5_Movie_Streaming_Platform[:5])

#Top 5 Streaming Platforms for combined data

# Concatenated both lists
Streaming_list= movie_streaming_list + tvshow_streaming_list

Streaming_Platorm_counts = Counter(Streaming_list)

# Step 3: Convert to DataFrame
df_Streaming_Platform = pd.DataFrame(Streaming_Platorm_counts.items(), columns=["Streaming Platform", "Count"])

# Step 4: Sort by frequency (descending)
df_Streaming_Platform = df_Streaming_Platform.sort_values(by="Count", ascending=False).reset_index(drop=True,  )

print("Top5 Streaming Platform Combined\n\n",df_Streaming_Platform[:5])

#Let's Visvalize it using word cloud
# Convert the combined list into a Dictionary
Streaming_Platform_dict = dict(zip(df_Streaming_Platform ["Streaming Platform"], df_Streaming_Platform ["Count"]))

# Generate word cloud
wordcloud_streaming_platform = WordCloud(width=800, height=400, background_color="white").generate_from_frequencies(Streaming_Platform_dict)

# Display
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud_streaming_platform, interpolation="bilinear")
plt.axis("off")
plt.show()

"""## **Data Export**"""

#saving final dataframe as Final Data in csv format
df_Movie.to_csv('Final_Movies_Data.csv', index=False)
Tv_Shows_df.to_csv('Final_Tv_Shows_Data.csv', index=False)

#saving filter data as Filter Data in csv format
filter_Moviedata_df.to_csv('Filtered_Movies_Data.csv', index=False)
filter_TvShowdata_df.to_csv('Filtered_Tv_Shows_Data.csv', index=False)